SHELL := /bin/bash

# Parallelise with all cores, if possible
NPROCS = $(shell grep -c 'processor' /proc/cpuinfo)
MAKEFLAGS += -j$(NPROCS)

# Names of tables in the postgres database to export to Cloud Storage
# and BigQuery
EXPORT = actions change_notes documents editions events expanded_links link_changes link_sets links path_reservations role_appointments roles unpublishings

# A step to create all the targets described in the CSV.GZ and BIGQUERY
# variables, which means that all the .sh and .sql scripts in the SH and
# BIGQUERY variables will be executed.
.PHONY: all
all: $(EXPORT)

actions:
	source functions.sh; export_to_bigquery table_name=$@

change_notes:
	source functions.sh; export_to_bigquery table_name=$@

documents:
	source functions.sh; export_to_bigquery table_name=$@

editions:
	source functions.sh; export_to_bigquery table_name=$@

events:
	source functions.sh; export_to_bigquery table_name=$@

expanded_links:
	source functions.sh; export_to_bigquery table_name=$@

link_changes:
	source functions.sh; export_to_bigquery table_name=$@

link_sets:
	source functions.sh; export_to_bigquery table_name=$@

links:
	source functions.sh; export_to_bigquery table_name=$@

path_reservations:
	source functions.sh; export_to_bigquery table_name=$@

role_appointments:
	source functions.sh; export_to_bigquery table_name=$@

roles:
	source functions.sh; export_to_bigquery table_name=$@

unpublishings:
	source functions.sh; export_to_bigquery table_name=$@
